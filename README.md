# GROMACS GPU Cloud Computing

A comprehensive repository for running GROMACS molecular dynamics simulations with GPU acceleration on cloud platforms. This repository provides scripts and configurations for deploying GROMACS on AWS EC2 and Azure Machine Learning platforms.

## ğŸ¯ Overview

This repository contains cloud-optimized scripts and configurations to:
- Install GROMACS with GPU support on cloud instances
- Run molecular dynamics simulations with GPU acceleration
- Deploy GROMACS jobs on AWS EC2 and Azure ML platforms
- Optimize performance and cost for cloud-based MD simulations

## ğŸ“ Repository Structure

```
gromacs-gpu-cloud/
â”œâ”€â”€ aws/                    # AWS EC2 deployment scripts
â”‚   â”œâ”€â”€ install_gromacs_gpu.sh    # Automated GROMACS installation script
â”‚   â”œâ”€â”€ run_md_aws.sh             # Script to run MD simulations on AWS
â”‚   â””â”€â”€ README.md                 # AWS-specific documentation
â”œâ”€â”€ azure-ml/               # Azure Machine Learning deployment
â”‚   â”œâ”€â”€ run_md.sh                 # Script to run MD simulations on Azure ML
â”‚   â”œâ”€â”€ gromacs-job.yml           # Azure ML job configuration
â”‚   â””â”€â”€ README.md                 # Azure ML-specific documentation
â”œâ”€â”€ .gitignore              # Git ignore patterns
â””â”€â”€ README.md               # This file
```

## ğŸš€ Quick Start

### AWS EC2 Deployment

1. **Launch an AWS G5 instance** (Ubuntu 24.04 LTS)
2. **Install GROMACS**:
   ```bash
   cd aws
   chmod +x install_gromacs_gpu.sh
   ./install_gromacs_gpu.sh
   ```
3. **Run simulations**:
   ```bash
   chmod +x run_md_aws.sh
   ./run_md_aws.sh
   ```

For detailed AWS instructions, see [aws/README.md](aws/README.md).

### Azure ML Deployment

1. **Configure Azure ML workspace**
2. **Submit job** using the provided YAML configuration
3. **Monitor** job execution in Azure ML portal

For detailed Azure ML instructions, see [azure-ml/README.md](azure-ml/README.md).

## ğŸ”§ Features

### AWS EC2
- âœ… Automated installation of GROMACS with CUDA GPU support
- âœ… NVIDIA driver and CUDA Toolkit 12.2 setup
- âœ… Optimized for G5 instance types (g5.xlarge, g5.2xlarge, etc.)
- âœ… GPU-accelerated MD simulation execution
- âœ… Cost-effective cloud computing for MD simulations

### Azure ML
- âœ… YAML-based job configuration
- âœ… Integration with Azure ML compute clusters
- âœ… GPU-enabled compute targets
- âœ… Scalable job submission and monitoring

## ğŸ“‹ Prerequisites

### AWS EC2
- AWS account with EC2 access
- G5 instance type (GPU-enabled)
- Ubuntu 24.04 LTS AMI
- SSH access with sudo privileges

### Azure ML
- Azure subscription
- Azure Machine Learning workspace
- GPU-enabled compute target

## ğŸ’» Usage Examples

### Running MD Simulation on AWS

```bash
# After installation, run your simulation
export GMX_GPU_DISABLE_COMPATIBILITY_CHECK=1
gmx mdrun -deffnm MD -nb gpu -v
```

### Key GROMACS Commands

- **Check version**: `gmx --version`
- **Verify GPU**: `nvidia-smi`
- **Run simulation**: `gmx mdrun -deffnm <prefix> -nb gpu -v`
- **Monitor GPU**: `watch -n 1 nvidia-smi`

## ğŸ’° Cost Optimization Tips

1. **Use Spot Instances**: Save up to 90% on AWS EC2 costs
2. **Right-size Instances**: Choose instance type based on simulation size
3. **Auto-shutdown**: Configure instances to stop when idle
4. **Batch Processing**: Group multiple simulations to maximize utilization
5. **Monitor Usage**: Track GPU utilization to optimize instance selection

## ğŸ” What Gets Installed

### System Components
- Build tools (gcc, g++, cmake)
- NVIDIA drivers (version 535)
- CUDA Toolkit 12.2
- OpenMPI for parallel execution
- FFTW libraries

### GROMACS Configuration
- GPU acceleration via CUDA
- MPI parallelization support
- Single precision build (faster, less memory)
- Optimized for cloud GPU instances

## ğŸ› Troubleshooting

### Common Issues

**GPU not detected**
- Verify instance type has GPU support
- Check NVIDIA driver installation: `nvidia-smi`
- Reboot instance if needed

**CUDA not found**
- Verify CUDA paths: `echo $PATH | grep cuda`
- Reload environment: `source ~/.bashrc`

**Build failures**
- Check disk space: `df -h`
- Verify memory: `free -h`
- Review installation logs

For platform-specific troubleshooting, refer to the respective README files.

## ğŸ“š Resources

- [GROMACS Documentation](https://manual.gromacs.org/)
- [AWS EC2 G5 Instances](https://aws.amazon.com/ec2/instance-types/g5/)
- [Azure Machine Learning](https://azure.microsoft.com/services/machine-learning/)
- [CUDA Toolkit Documentation](https://docs.nvidia.com/cuda/)

## ğŸ¤ Contributing

Contributions are welcome! Please ensure:
- Scripts are tested on respective cloud platforms
- Documentation is updated
- Code follows existing style conventions

## ğŸ“ License

This repository is provided as-is for educational and research purposes.

## ğŸ”„ Version Information

- **GROMACS**: Latest from GitHub repository
- **CUDA**: 12.2
- **NVIDIA Driver**: 535
- **Ubuntu**: 24.04 LTS

## ğŸ“§ Support

For issues or questions:
1. Check the platform-specific README files
2. Review troubleshooting sections
3. Consult GROMACS and cloud provider documentation

---

**Note**: Always ensure you have proper input files (`.tpr`, `.gro`, `.mdp`) prepared before running simulations. Monitor GPU utilization and instance costs regularly to optimize your cloud computing expenses.
